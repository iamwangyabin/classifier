arch: "coop"  # Architecture for binary classification, e.g., 'resnet50.tv_in1k' 'vit_base_patch16_224'
resume: null
name: "multiclass-ViTLâ€”Progan"  # Name of the experiment for organizing samples and models

train:
  gpu_ids: [2]  # GPU IDs to use for training, e.g., '0' for single GPU or '0,1,2,3' for multiple GPUs
  train_epochs: 10  # Number of training epochs
  gradient_accumulation_steps: 1
  check_val_every_n_epoch: 1

  optimizer:
    _target_: torch.optim.AdamW
    _partial_: True
    lr: 1e-4
    weight_decay: 1e-3

  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: True
    T_max: 10

model:
  NAME: "ViT-L/14"
  N_CTX: 16
  CSC: False
  CTX_INIT: "a photo of a"
  CLASS_TOKEN_POSITION: "end"


dataset:
  train:
    dataroot: "/home/jwang/ybwork/data/deepfake_benchmark/ForenSynths/train"
    batch_size: 128
    loader_workers: 32
    loadSize: 256
    cropSize: 224
    random_flip: true
    augment: null

  val:
    dataroot: "/home/jwang/ybwork/data/deepfake_benchmark/ForenSynths/val"
    batch_size: 64
    loader_workers: 4
    loadSize: 256
    cropSize: 224


