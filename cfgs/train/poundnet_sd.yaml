arch: "arp"
resume: null
name: "arp-ViTL-001-881"

train:
  pipeline: engine.poundnet_trainer

  gpu_ids: [0]
  train_epochs: 10
  gradient_accumulation_steps: 1
  check_val_every_n_epoch: 1

  a: 0
  b: 0
  c: 1

  optimizer:
    _target_: torch.optim.AdamW
    _partial_: True
    lr: 1e-4
    weight_decay: 1e-3

  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: True
    T_max: 10

model:
  NAME: "ViT-L/14"
  N_CTX_VISION: 16
  N_CTX_TEXT: 16
  CTX_INIT: False
  PROMPT_DEPTH_VISION: 8
  PROMPT_DEPTH_TEXT: 8
  PROMPT_NUM_TEXT: 1

datasets:
  train:
    data_root: "/scratch/yw26g23/datasets/deepfakebenchmark/our"
    sub_sets: ["all"]
    split: 'train_binary'
    multicalss_names: [ "airplane", "bird", "bottle", "car", "chair", "diningtable", "horse", "person", "sheep", "train",
                        "bicycle", "boat", "bus", "cat", "cow", "dog", "motorbike", "pottedplant", "sofa", "tvmonitor" ]
    batch_size: 256
    loader_workers: 32
    trsf:
      - _target_: torchvision.transforms.Resize
        size: 256
        interpolation: 3
      - _target_: torchvision.transforms.RandomResizedCrop
        size: 224
      - _target_: torchvision.transforms.RandomHorizontalFlip
      - _target_: data.DataAugment
        blur_prob: 0.1
        blur_sig: [0.0, 1.0]
        jpg_prob: 0.1
        jpg_method: ['cv2', 'pil']
        jpg_qual: [60, 100]
      - _target_: torchvision.transforms.ToTensor
      - _target_: torchvision.transforms.Normalize
        mean: [0.48145466, 0.4578275, 0.40821073]
        std: [0.26862954, 0.26130258, 0.27577711]


  val:
    data_root: "/scratch/yw26g23/datasets/deepfakebenchmark/ForenSynths"
    sub_sets: [ "biggan", "crn", "cyclegan", "deepfake", "gaugan", "imle", "progan", "san", "seeingdark", "stargan",
                "stylegan", "stylegan2", "whichfaceisreal" ]
    split: 'test'
    batch_size: 128
    loader_workers: 32
    trsf:
      - _target_: data.RandomCompress
        method: "JPEG"
        qf: [70, 100]
      - _target_: torchvision.transforms.Resize
        size: 256
        interpolation: 3
      - _target_: torchvision.transforms.RandomResizedCrop
        size: 224
      - _target_: torchvision.transforms.ToTensor
      - _target_: torchvision.transforms.Normalize
        mean: [0.48145466, 0.4578275, 0.40821073]
        std: [0.26862954, 0.26130258, 0.27577711]


