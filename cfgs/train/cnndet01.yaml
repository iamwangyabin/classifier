arch: "cnn"
resume: null
name: "cnndet01_progan"

#      Imagenet:
#      mean: [ 0.485, 0.456, 0.406 ]
#      std: [ 0.229, 0.224, 0.225 ]
#      CLIP:
#      mean: [0.48145466, 0.4578275, 0.40821073]
#      std: [0.26862954, 0.26130258, 0.27577711]

train:
  pipeline: engine.base_trainer

  gpu_ids: [0]
  train_epochs: 1
  gradient_accumulation_steps: 1
  check_val_every_n_epoch: 1

  optimizer:
    _target_: torch.optim.AdamW
    _partial_: True
    lr: 1e-4
    weight_decay: 1e-3

  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: True
    T_max: 1

datasets:
  train:
#    data_root: "/scratch/yw26g23/datasets/deepfakebenchmark/ForenSynths"
    data_root: "/home/jwang/ybwork/data/DFBenchmark/ForenSynths"
    sub_sets: ["airplane", "bird", "bottle", "car", "chair", "diningtable", "horse", "person", "sheep", "train",
               "bicycle", "boat", "bus", "cat", "cow", "dog", "motorbike", "pottedplant", "sofa", "tvmonitor"]
    batch_size: 128
    loader_workers: 32
    trsf:
      - _target_: torchvision.transforms.Resize
        size: 256
      - _target_: torchvision.transforms.RandomResizedCrop
        size: 224
      - _target_: torchvision.transforms.RandomHorizontalFlip
      - _target_: data.DataAugment
        blur_prob: 0.1
        blur_sig: [0.0, 3.0]
        jpg_prob: 0.1
        jpg_method: ['cv2', 'pil']
        jpg_qual: [30, 100]
      - _target_: torchvision.transforms.ToTensor
      - _target_: torchvision.transforms.Normalize
        mean: [ 0.485, 0.456, 0.406 ]
        std: [ 0.229, 0.224, 0.225 ]





  val:
    data_root: "/home/jwang/ybwork/data/DFBenchmark/ForenSynths"
#    data_root: "/scratch/yw26g23/datasets/deepfakebenchmark/ForenSynths/test"
    sub_sets: ["airplane", "bird", "bottle", "car", "chair", "diningtable", "horse", "person", "sheep", "train",
               "bicycle", "boat", "bus", "cat", "cow", "dog", "motorbike", "pottedplant", "sofa", "tvmonitor"]
    batch_size: 128
    loader_workers: 32
    trsf:
      - _target_: torchvision.transforms.Resize
        size: 256
      - _target_: torchvision.transforms.RandomResizedCrop
        size: 224
      - _target_: torchvision.transforms.ToTensor
      - _target_: torchvision.transforms.Normalize
        mean: [ 0.485, 0.456, 0.406 ]
        std: [ 0.229, 0.224, 0.225 ]


